{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use gradio library.\n",
    "To use gradio, we'll need to install it with `pip install gradio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import openai\n",
    "\n",
    "openai.api_key = open(\"key.txt\", \"r\").read().strip(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulate to start with message_history:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = [{\"role\": \"user\", \"content\": f\"You are a joke bot. I will specify the subject matter in my messages, and you will reply with a joke that includes the subjects I mention in my messages. Reply only with jokes to further input. If you understand, say OK.\"},\n",
    "                   {\"role\": \"assistant\", \"content\": f\"OK\"}]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll inject the assistant's reply of \"OK\" to encourage it to do what I've asked. Next, we'll make a predict function, which is similar to our chat function from before, but is merged with the demo predict function from a gradio example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input):\n",
    "    # tokenize the new input sentence\n",
    "    message_history.append({\"role\": \"user\", \"content\": f\"{input}\"})\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=message_history\n",
    "    )\n",
    "    #Just the reply text\n",
    "    reply_content = completion.choices[0].message.content#.replace('```python', '<pre>').replace('```', '</pre>')\n",
    "    \n",
    "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"}) \n",
    "    \n",
    "    # get pairs of msg[\"content\"] from message history, skipping the pre-prompt:              here.\n",
    "    response = [(message_history[i][\"content\"], message_history[i+1][\"content\"]) for i in range(2, len(message_history)-1, 2)]  # convert to tuples of list\n",
    "    return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can build the gradio app. To make things easier, I'll comment what each line does here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new Blocks app and assigns it to the variable demo.\n",
    "with gr.Blocks() as demo: \n",
    "\n",
    "    # creates a new Chatbot instance and assigns it to the variable chatbot.\n",
    "    chatbot = gr.Chatbot() \n",
    "\n",
    "    # creates a new Row component, which is a container for other components.\n",
    "    with gr.Row(): \n",
    "        '''creates a new Textbox component, which is used to collect user input. \n",
    "        The show_label parameter is set to False to hide the label, \n",
    "        and the placeholder parameter is set'''\n",
    "        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n",
    "    '''\n",
    "    sets the submit action of the Textbox to the predict function, \n",
    "    which takes the input from the Textbox, the chatbot instance, \n",
    "    and the state instance as arguments. \n",
    "    This function processes the input and generates a response from the chatbot, \n",
    "    which is displayed in the output area.'''\n",
    "    txt.submit(predict, txt, chatbot) # submit(function, input, output)\n",
    "    #txt.submit(lambda :\"\", None, txt)  #Sets submit action to lambda function that returns empty string \n",
    "\n",
    "    '''\n",
    "    sets the submit action of the Textbox to a JavaScript function that returns an empty string. \n",
    "    This line is equivalent to the commented out line above, but uses a different implementation. \n",
    "    The _js parameter is used to pass a JavaScript function to the submit method.'''\n",
    "    txt.submit(None, None, txt, _js=\"() => {''}\") # No function, no input to that function, submit action to textbox is a js function that returns empty string, so it clears immediately.\n",
    "         \n",
    "demo.launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we have the full app with Gradio like here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import openai\n",
    "\n",
    "openai.api_key = open(\"key.txt\", \"r\").read().strip(\"\\n\")\n",
    "\n",
    "message_history = [{\"role\": \"user\", \"content\": f\"You are a joke bot. I will specify the subject matter in my messages, and you will reply with a joke that includes the subjects I mention in my messages. Reply only with jokes to further input. If you understand, say OK.\"},\n",
    "                   {\"role\": \"assistant\", \"content\": f\"OK\"}]\n",
    "\n",
    "def predict(input):\n",
    "    # tokenize the new input sentence\n",
    "    message_history.append({\"role\": \"user\", \"content\": f\"{input}\"})\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\", #10x cheaper than davinci, and better. $0.002 per 1k tokens\n",
    "      messages=message_history\n",
    "    )\n",
    "    #Just the reply:\n",
    "    reply_content = completion.choices[0].message.content#.replace('```python', '<pre>').replace('```', '</pre>')\n",
    "\n",
    "    print(reply_content)\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"}) \n",
    "    \n",
    "    # get pairs of msg[\"content\"] from message history, skipping the pre-prompt:              here.\n",
    "    response = [(message_history[i][\"content\"], message_history[i+1][\"content\"]) for i in range(2, len(message_history)-1, 2)]  # convert to tuples of list\n",
    "    return response\n",
    "\n",
    "# creates a new Blocks app and assigns it to the variable demo.\n",
    "with gr.Blocks() as demo: \n",
    "\n",
    "    # creates a new Chatbot instance and assigns it to the variable chatbot.\n",
    "    chatbot = gr.Chatbot() \n",
    "\n",
    "    # creates a new Row component, which is a container for other components.\n",
    "    with gr.Row(): \n",
    "        '''creates a new Textbox component, which is used to collect user input. \n",
    "        The show_label parameter is set to False to hide the label, \n",
    "        and the placeholder parameter is set'''\n",
    "        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n",
    "    '''\n",
    "    sets the submit action of the Textbox to the predict function, \n",
    "    which takes the input from the Textbox, the chatbot instance, \n",
    "    and the state instance as arguments. \n",
    "    This function processes the input and generates a response from the chatbot, \n",
    "    which is displayed in the output area.'''\n",
    "    txt.submit(predict, txt, chatbot) # submit(function, input, output)\n",
    "    #txt.submit(lambda :\"\", None, txt)  #Sets submit action to lambda function that returns empty string \n",
    "\n",
    "    '''\n",
    "    sets the submit action of the Textbox to a JavaScript function that returns an empty string. \n",
    "    This line is equivalent to the commented out line above, but uses a different implementation. \n",
    "    The _js parameter is used to pass a JavaScript function to the submit method.'''\n",
    "    txt.submit(None, None, txt, _js=\"() => {''}\") # No function, no input to that function, submit action to textbox is a js function that returns empty string, so it clears immediately.\n",
    "         \n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
