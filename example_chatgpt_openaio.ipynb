{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start these simple test, we have to follow chatgpt guideline to create a ChatGPT token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = open(\"token.txt\", \"r\").read().strip(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will create a function to call to OpenAI and inquire a question.\n",
    "- In each question, we take a couple of tokens with prices: `# this is \"ChatGPT: gpt-3.5-turbo\" $0.002 per 1k tokens`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  messages=[{\"role\": \"user\", \"content\": \"What is the winner in Premier Leage 2023?\"}]\n",
    ")\n",
    "print(question_completion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse content of return from chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_content = question_completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HÆ¡ to manage chat history, we can sort of message history variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = []\n",
    "# What is the winner in Premier Leage 2023?\n",
    "user_input = input(\"> \")\n",
    "print(\"User's input was: \", user_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return should be: `User's input was:  What is the moon's circumference in km?`\n",
    "Now that you have the user input, let's format it for the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.append({\"role\": \"user\", \"content\": f\"{user_input}\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use OpenAI to query history message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=message_history\n",
    ")\n",
    "\n",
    "# Now we can print the response:\n",
    "reply_content = completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting a reply_content repsonse, you'll want to append it to the history:\n",
    "# note the use of the \"assistant\" role here. This is because we're feeding the model's response into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = []\n",
    "\n",
    "def chat(inp, role=\"user\"):\n",
    "    message_history.append({\"role\": role, \"content\": f\"{inp}\"})\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=message_history\n",
    "    )\n",
    "    reply_content = completion.choices[0].message.content\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
    "    return reply_content\n",
    "\n",
    "for i in range(2):\n",
    "    user_input = input(\"> \")\n",
    "    print(\"User's input was: \", user_input)\n",
    "    print(chat(user_input))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
